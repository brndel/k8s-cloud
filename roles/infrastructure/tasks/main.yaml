- name: Set dynamic facts
  vars:
    suffix: "{{ domain | community.dns.get_public_suffix }}"
    main_name: "{{ domain | replace(suffix, '') | split('.') | last }}"
  ansible.builtin.set_fact:
    cluster_fqn: "{{ subdomains.cluster }}.{{ domain }}"
    charts_dir: "{{ playbook_dir }}/charts"
    cluster_name: "{{ vcluster | ternary(domain | replace('.', '-'), 'default') }}"
    registered_domain: "{{ main_name }}{{ suffix }}"

- name: Print domain info
  ansible.builtin.debug:
    msg: "Setting up cluster '{{ cluster_fqn }}' for domain '{{ domain }}' on registered domain '{{ registered_domain }}'"

- name: Get current kubectl context
  ansible.builtin.command: "kubectl config current-context"
  changed_when: false
  register: default_ctx

- name: Ensure cluster FQN label is applied to nodes
  block:
    - name: Get all k8s nodes
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Node
      register: all_k8s_nodes

    - name: Filter out nodes as per inventory
      ansible.builtin.set_fact:
        inventory_nodes: "{{ all_k8s_nodes.resources | json_query(node_filter) | json_query(node_extractor) }}"
      vars:
        node_filter: '[?contains({{ groups["all"] }}, metadata.annotations."k3s.io/external-ip")]'
        node_extractor: '[].metadata.annotations."k3s.io/hostname"'

    - name: Add cluster FQN as label to all inventory nodes
      loop: "{{ inventory_nodes }}"
      kubernetes.core.k8s:
        state: patched
        kind: Node
        name: "{{ item }}"
        definition:
          metadata:
            labels: "{{ {cluster_fqn: '1'} }}"

- name: Ensure vcluster for domain exists
  when: "vcluster"
  block:
    - name: Ensure vcluster helm release exists
      kubernetes.core.helm:
        wait: true
        name: vcluster
        release_namespace: "{{ cluster_name }}"
        create_namespace: true
        chart_repo_url: https://charts.loft.sh
        chart_ref: vcluster
        chart_version: "^0.15"
        values:
          sync:
            persistentvolumes:
              enabled: true
            storageclasses:
              enabled: true
            volumesnapshots:
              enabled: true
            nodes:
              enabled: true
              enableScheduler: true
              nodeSelector: "{{ cluster_fqn }}=1"
            ingresses:
              enabled: true
            networkpolicies:
              enabled: true
          proxy:
            metricsServer:
              nodes:
                enabled: true
              pods:
                enabled: true
          syncer:
            extraArgs:
              - "--tls-san={{ cluster_fqn }}"
          vcluster:
            extraArgs:
              - "--kube-apiserver-arg=oidc-issuer-url=https://{{ subdomains.idp }}.{{ domain }}/realms/master"
              - "--kube-apiserver-arg=oidc-client-id=cluster-oidc"
              - "--kube-apiserver-arg=oidc-groups-claim=groups"

    - name: Gather facts on listening ports
      community.general.listen_ports_facts:
        include_non_listening: true

    - name: Switch kube-context to vcluster
      vars:
        used_ports: "{{ ansible_facts.tcp_listen | map(attribute='port') | list }}"
      ansible.builtin.set_fact:
        vcluster_port: "{{ range(5000, 30000) | list | difference(used_ports) | random }}"

    - name: Switch kube-context to vcluster
      vars:
        connect_args: "--kube-config-context-name {{ cluster_name }} --local-port {{ vcluster_port }}"
      ansible.builtin.shell: "nohup vcluster connect vcluster -n {{ cluster_name }} {{ connect_args }} </dev/null >/dev/null 2>&1 &"
      changed_when: true
      register: vcluster_connect

    - name: Print port where vcluster listens
      ansible.builtin.debug:
        msg: "VCluster API is being forwarded to port {{ vcluster_port }} on localhost"

    - name: Wait for port-forwarded vcluster API to become available
      ansible.builtin.wait_for:
        host: localhost
        port: "{{ vcluster_port }}"
        timeout: 120

- name: Ensure kubeconfig file is available on local machine
  block:
    - name: Copy default kubeconfig file
      ansible.builtin.copy:
        remote_src: true
        src: "{{ ansible_env.KUBECONFIG }}"
        dest: /tmp/kubeconfig.yaml
        mode: '0644'

    - name: Change server address of copied kubeconfig to public cluster FQN
      ansible.builtin.command:
        argv:
          - kubectl
          - config
          - set-cluster
          - "{{ cluster_name }}"
          - "--server=https://{{ cluster_fqn }}"
      environment:
        KUBECONFIG: /tmp/kubeconfig.yaml
      changed_when: true

    - name: Download kubeconfig file
      ansible.builtin.fetch:
        src: /tmp/kubeconfig.yaml
        dest: "{{ playbook_dir }}/{{ cluster_name }}.kubeconfig.yaml"
        flat: true

- name: Ensure GitOps is setup
  block:
    - name: Check if FluxCD release already exists
      kubernetes.core.helm_info:
        name: fluxcd
        release_namespace: flux-system
      register: existing_fluxcd

    - name: Deploy FluxCD
      when: "existing_fluxcd.status is undefined or existing_fluxcd.status.keys() | length == 0"
      kubernetes.core.helm:
        wait: true
        timeout: 10m
        name: fluxcd
        release_namespace: flux-system
        create_namespace: true
        chart_repo_url: https://fluxcd-community.github.io/helm-charts
        chart_ref: flux2
        chart_version: "^2"
        values:
          policies:
            create: false

    - name: Ensure base GitRepository exists
      kubernetes.core.k8s:
        wait: true
        definition:
          apiVersion: source.toolkit.fluxcd.io/v1
          kind: GitRepository
          metadata:
            name: base-repo
            namespace: flux-system
          spec:
            interval: 1h
            url: "{{ base_repo }}"
            ref:
              branch: "{{ base_branch }}"

    - name: Reconcile base git repo
      ansible.builtin.command: "flux reconcile source git base-repo -n flux-system"
      changed_when: true

- name: Bootstrap components with CRDs and other hard dependecies (via minimal-config release)
  block:
    - name: Bootstrap host-cluster infrastructure
      when: "not vcluster"
      ansible.builtin.include_tasks:
        file: bootstrap-chart.yaml
        apply:
          vars:
            chart: "{{ item }}"
      loop:
        - name: storage-stack
          namespace: longhorn-system
        - name: cert-stack
          namespace: cert-system
        - name: ingress-stack
          namespace: ingress-system

    - name: Bootstrap cluster infrastructure
      ansible.builtin.include_tasks:
        file: bootstrap-chart.yaml
        apply:
          vars:
            chart: "{{ item }}"
      loop:
        - name: telemetry-stack
          namespace: telemetry-system
        - name: cicd-stack
          namespace: flux-system

- name: Ensure all required secrets exist
  kubernetes.core.k8s:
    wait: true
    definition:
      apiVersion: v1
      kind: Secret
      metadata:
        name: "{{ item.name }}"
        namespace: kube-system
      type: Opaque
      data:
        secret: "{{ vars[item.inventoryKey] | b64encode }}"
  loop:
    - inventoryKey: smtp_password
      name: smtp
    - inventoryKey: s3_access_key_secret
      name: s3
    - inventoryKey: external_dns_token
      name: external-dns

- name: Ensure HelmReleases for host-cluster infrastructure exist
  when: "not vcluster"
  ansible.builtin.include_tasks:
    file: deploy-chart.yaml
    apply:
      vars:
        chart: "{{ item }}"
  loop_control:
    label: "{{ item.name }} in {{ item.namespace }}"
  loop:
    - name: upgrade-controller
      namespace: kube-system

    - name: namespace-isolation
      namespace: longhorn-system

    - name: storage-stack
      namespace: longhorn-system
      chart_values:
        host: "{{ subdomains.storage }}.{{ domain }}"
        oauth2_proxy_host: "{{ subdomains.auth }}.{{ domain }}"
        admin_group: "cluster-admins"
        s3: "{{ s3 | combine({'access_key_secret': {'name': 's3', 'namespace': 'kube-system', 'key': 'secret'}, 'bucket': s3_buckets.backup}) }}"

    - name: namespace-isolation
      namespace: cert-system

    - name: cert-stack
      namespace: cert-system
      chart_values:
        admin_email: "{{ admin_email }}"
        base_repo: "{{ base_repo }}"
        base_branch: "{{ base_branch }}"
        letsencrypt_staging: "{{ letsencrypt_staging }}"

    - name: namespace-isolation
      namespace: ingress-system

    - name: ingress-stack
      namespace: ingress-system

    - name: namespace-isolation
      namespace: backup-system

    - name: backup-stack
      namespace: backup-system
      chart_values:
        s3: "{{ s3 | combine({'access_key_secret': {'name': 's3', 'namespace': 'kube-system', 'key': 'secret'}, 'bucket': s3_buckets.backup}) }}"

- name: Ensure cluster FQN label is applied to Longhorn nodes
  when: "not vcluster"
  block:
    - name: Get list of current Longhorn node tags
      loop: "{{ inventory_nodes }}"
      kubernetes.core.k8s_info:
        api_version: longhorn.io/v1beta2
        kind: Node
        namespace: longhorn-system
        name: "{{ item }}"
        wait: true
        wait_timeout: 180
        wait_condition:
          type: Ready
          status: "True"
      register: lhn_info

    - name: Ensure cluster FQN is tag on all Longhorn nodes in inventory
      loop: "{{ lhn_info.results }}"
      loop_control:
        label: "{{ item.item }}"
      vars:
        existing_tags: "{{ item.resources[0].spec.tags }}"
        lhn_name: "{{ item.resources[0].metadata.name }}"
      kubernetes.core.k8s:
        state: patched
        api_version: longhorn.io/v1beta2
        kind: Node
        namespace: longhorn-system
        name: "{{ lhn_name }}"
        definition:
          spec:
            tags: "{{ (existing_tags + [cluster_fqn]) | unique | list }}"
      register: lhn_patch_result
      retries: 6 # Longhorn CRD webhook tends to be unavailable at times.
      delay: 20
      until: "lhn_patch_result is not failed"

- name: Apply backup restoration, if supplied
  when: "not vcluster and restore_from_backup"
  kubernetes.core.k8s:
    wait: true
    definition:
      apiVersion: velero.io/v1
      kind: Restore
      metadata:
        name: initial-cluster-restore
        namespace: backup-system
      spec:
        backupName: "{{ restore_from_backup }}"

- name: Expose k8s API via Ingress
  kubernetes.core.k8s:
    wait: true
    definition:
      apiVersion: networking.k8s.io/v1
      kind: Ingress
      metadata:
        name: k8s-api
        namespace: default
        annotations:
          nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
          nginx.ingress.kubernetes.io/ssl-passthrough: "true"
          nginx.ingress.kubernetes.io/ssl-redirect: "true"
      spec:
        rules:
          - host: "{{ cluster_fqn }}"
            http:
              paths:
                - backend:
                    service:
                      name: kubernetes
                      port:
                        number: 443
                  path: /
                  pathType: ImplementationSpecific
  register: k8s_ingress_result
  retries: 6 # NGINX webhook tends to be unavailable at times.
  delay: 20
  until: "k8s_ingress_result is not failed"

- name: Ensure HelmReleases for cluster infrastructure exist
  ansible.builtin.include_tasks:
    file: deploy-chart.yaml
    apply:
      vars:
        chart: "{{ item }}"
  loop_control:
    label: "{{ item.name }} in {{ item.namespace }}"
  loop:
    - name: admin-rbac
      namespace: kube-system
      chart_values:
        admin_group: "cluster-admins"

    - name: crypto-storage
      namespace: longhorn-system
      chart_values:
        cluster_fqn: "{{ cluster_fqn }}"

    - name: namespace-isolation
      namespace: dns-system

    - name: dns-stack
      namespace: dns-system
      chart_values:
        domain: "{{ registered_domain }}"
        token_secret:
          namespace: kube-system
          name: external-dns
          key: secret

    - name: sso-stack
      namespace: sso-system
      chart_values:
        domain: "{{ domain }}"
        org: "{{ org }}"
        hosts:
          keycloak: "{{ subdomains.idp }}.{{ domain }}"
          authproxy: "{{ subdomains.auth }}.{{ domain }}"
        clients:
          oidc:
            - id: cluster-oidc
              redirect_uris:
                - "https://{{ subdomains.telemetry }}.{{ domain }}/login/generic_oauth"
                - "https://{{ subdomains.gitops }}.{{ domain }}/oauth2/callback"
                - "http://localhost:8000/"
        smtp: "{{ smtp | combine({'password_secret': {'name': 'smtp', 'namespace': 'kube-system', 'key': 'secret'}}) }}"
        admin_group: "cluster-admins"
        admin_email: "{{ admin_email }}"
        letsencrypt_staging: "{{ letsencrypt_staging }}"

    - name: namespace-isolation
      namespace: telemetry-system

    - name: telemetry-stack
      namespace: telemetry-system
      chart_values:
        domain: "{{ domain }}"
        org: "{{ org }}"
        host: "{{ subdomains.telemetry }}.{{ domain }}"
        oidc_client:
          idp_url: "https://{{ subdomains.idp }}.{{ domain }}/realms/master"
          id: "cluster-oidc"
          secret:
            namespace: sso-system
            name: "oidc-client.cluster-oidc"
            key: secret
        admin_email: "{{ admin_email }}"
        admin_group: "cluster-admins"
        s3: "{{ s3 | combine({'access_key_secret': {'name': 's3', 'namespace': 'kube-system', 'key': 'secret'}, 'bucket': s3_buckets.logs}) }}"
        smtp: "{{ smtp | combine({'password_secret': {'name': 'smtp', 'namespace': 'kube-system', 'key': 'secret'}}) }}"
        node_endpoints: "{{ groups['all'] }}"
        letsencrypt_staging: "{{ letsencrypt_staging }}"
        k3s: "{{ not vcluster }}"

    - name: namespace-isolation
      namespace: flux-system

    - name: cicd-stack
      namespace: flux-system
      chart_values:
        host: "{{ subdomains.gitops }}.{{ domain }}"
        oidc_client:
          idp_url: "https://{{ subdomains.idp }}.{{ domain }}/realms/master"
          id: "cluster-oidc"
          secret:
            namespace: sso-system
            name: "oidc-client.cluster-oidc"
            key: secret
        letsencrypt_staging: "{{ letsencrypt_staging }}"

    - name: control-stack
      namespace: kube-system
      chart_values:
        host: "{{ subdomains.control }}.{{ domain }}"
        oauth2_proxy_host: "{{ subdomains.auth }}.{{ domain }}"
        admin_group: "cluster-admins"

- name: Reset cluster context
  when: "vcluster"
  block:
    - name: Reset kubectl context to default
      ansible.builtin.command: "kubectl config use-context {{ default_ctx.stdout }}"
      changed_when: true

    - name: Get PIDs of running vcluster port-forwarders
      community.general.pids:
        name: vcluster
      register: vcluster_pids

    - name: Terminate port-forwarding to vcluster
      loop: "{{ vcluster_pids.pids }}"
      ansible.builtin.command: "kill -SIGTERM {{ item }}"
      changed_when: true

- name: Ensure vcluster namespace is isolated
  when: "vcluster"
  ansible.builtin.include_tasks:
    file: deploy-chart.yaml
    apply:
      vars:
        chart:
          name: namespace-isolation
          namespace: "{{ cluster_name }}"
